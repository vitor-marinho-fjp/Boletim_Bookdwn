[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": " Compartilhando o código em R",
    "section": "",
    "text": "Prefacio\nÉ com grande satisfação que apresentamos este livro de tutoriais em R para transformação digital, elaborado pela Diretoria de Estatística da Fundação João Pinheiro. Este livro foi criado com o objetivo de oferecer a você uma coleção de recursos valiosos para aprimorar suas habilidades em análise de dados e promover a transformação digital em seus projetos de pesquisa."
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introdução",
    "section": "",
    "text": "A linguagem de programação R desempenha um papel fundamental em nossa abordagem. R é uma linguagem de código aberto e um ambiente de análise estatística que se tornou amplamente reconhecido e utilizado por pesquisadores, cientistas de dados e profissionais de análise em todo o mundo. Suas vantagens para pesquisadores são notáveis e incluem:\n\nFlexibilidade e Poder Estatístico: R oferece uma vasta gama de pacotes e bibliotecas estatísticas que permitem a realização de análises complexas e avançadas. Sua flexibilidade permite que pesquisadores implementem métodos personalizados e testem hipóteses de forma eficaz.\nVisualização de Dados: R é altamente elogiado por sua capacidade de criar visualizações de dados de alta qualidade. Gráficos e gráficos gerados com R são essenciais para comunicar resultados de pesquisa de forma clara e eficaz.\nComunidade Ativa: R possui uma comunidade de usuários ativos e colaborativos, o que significa que você pode encontrar suporte, recursos e soluções para seus desafios de programação e análise em fóruns e grupos de discussão dedicados.\nCódigo Aberto e Gratuito: R é uma linguagem de código aberto, o que significa que é acessível para todos, independentemente das restrições financeiras. Isso é especialmente vantajoso para pesquisadores acadêmicos e organizações sem fins lucrativos.\nReprodutibilidade: R promove a reprodutibilidade em pesquisas. Com o uso de scripts e notebooks, é possível documentar e compartilhar com precisão as etapas de análise de dados, tornando os resultados mais transparentes e confiáveis.\nIntegração com Outras Linguagens e Ferramentas: R pode ser facilmente integrado com outras linguagens de programação e ferramentas, permitindo que pesquisadores aproveitem ao máximo suas habilidades e recursos existentes.\n\nAo longo das páginas deste livro, você aprenderá como aproveitar essas vantagens da linguagem R em suas pesquisas e projetos de análise de dados, com um foco especial em ferramentas que podem ser extremamente úteis no dia a dia dos pesquisadores da Fundação João Pinheiro.\nNossa missão é capacitar você a tomar decisões informadas, resolver problemas complexos e impulsionar o sucesso de seus projetos de pesquisa. Este livro é um convite para explorar, aprender e crescer em sua jornada de transformação digital por meio da análise de dados com a linguagem R.\nEstamos empolgados em compartilhar nosso conhecimento e experiência com você e esperamos que esses tutoriais sejam recursos valiosos em sua busca por excelência na pesquisa e análise de dados."
  },
  {
    "objectID": "02-BO_01_Gini.html",
    "href": "02-BO_01_Gini.html",
    "title": "2  Índice de Gini",
    "section": "",
    "text": "3 Medidas de Desigualdade\nO Índice de Gini é uma medida estatística amplamente utilizada para avaliar a desigualdade na distribuição de renda em uma população ou país. Ele fornece uma medida numérica que varia de 0 a 1, onde 0 representa igualdade perfeita (ou seja, todas as pessoas possuem a mesma renda) e 1 representa desigualdade máxima (ou seja, uma única pessoa detém toda a renda, enquanto as demais não possuem nenhuma) (Hoffmann 2006).\nAo calcular o Índice de Gini, é possível obter uma compreensão clara do quão desigual é a distribuição de renda em uma sociedade. Ele é frequentemente usado por economistas, pesquisadores e formuladores de políticas públicas para medir e comparar a desigualdade em diferentes regiões e ao longo do tempo. Com base nessa medida, é possível identificar áreas de alta desigualdade e direcionar esforços para promover políticas sociais e econômicas mais igualitárias.\nAqui estão alguns exemplos de problemas de pesquisa que podem ser analisados usando esse índice:\nEsses são apenas alguns exemplos, e existem inúmeras questões de pesquisa que podem ser abordadas usando o Índice de Gini como medida de desigualdade de renda.\nCada problema pode exigir abordagens metodológicas diferentes e fontes de dados específicas, mas o Índice de Gini oferece uma base sólida para explorar e compreender questões relacionadas à desigualdade socioeconômica.\nNeste tutorial, você aprenderá como calcular o Índice de Gini no R usando dados de PIB municipal e população. Antes de começar, certifique-se de ter os pacotes necessários instalados. Caso contrário, você pode instalá-los usando a função install.packages()."
  },
  {
    "objectID": "02-BO_01_Gini.html#cálculo-do-índice-de-gini",
    "href": "02-BO_01_Gini.html#cálculo-do-índice-de-gini",
    "title": "2  Índice de Gini",
    "section": "3.1 Cálculo do Índice de Gini",
    "text": "3.1 Cálculo do Índice de Gini\nO Índice de Gini é calculado da seguinte maneira:\n\\[\nG = \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n} |x_i - x_j|\n\\]\nOnde: - (G) é o Índice de Gini. - (n) é o número de observações na amostra. - (x_i) são os valores ordenados da variável de renda. - (x_j) são os valores ordenados da mesma variável de renda. - (||) é o valor absoluto. - () é a média da variável de renda."
  },
  {
    "objectID": "03-BO_02_Datamaid.html",
    "href": "03-BO_02_Datamaid.html",
    "title": "3  Workshop: Crítica e Imputação de Dados: Pacote DataMaid",
    "section": "",
    "text": "4 Introdução\nNesta oficina, aprenderemos como usar o pacote DataMaid no R para uma etapa prévia a crítica de dados: a preparação dos dados.\nTutorial disponível: https://github.com/vitor-marinho-fjp/Critica_Datamaid\nO que é o DataMaid?\nUm assistente de limpeza de dados capaz de fornecer um documento para ser lido e avaliado por uma pessoa. Uma ferramenta para auxiliar na lógica/verificação de erros tanto em colunas quanto em linhas. (Petersen e Ekstrøm 2019)\nAlém da análise inicial, você pode criar regras personalizadas para a análise inicial dos dados.\nPor exemplo, podemos verificar a variável S_TXBRUTAMORT\nTrace a distribuição de uma variável.\nMarinho,V.; Gonçalves, C. Preparação de Dados: Pacote DataMaid. Tutorial Transformação Digital. Fundação João Pinheiro, n. 2, 2023. Disponível em: https://rpubs.com/fjp/datamaid."
  },
  {
    "objectID": "03-BO_02_Datamaid.html#pacotes-utilizados",
    "href": "03-BO_02_Datamaid.html#pacotes-utilizados",
    "title": "3  Workshop: Crítica e Imputação de Dados: Pacote DataMaid",
    "section": "5.1 Pacotes utilizados",
    "text": "5.1 Pacotes utilizados\n\n### Instalação e Carregamento do Pacote\n\n# Lista de pacotes necessários\npacotes <- c('dataMaid', 'tidyverse', 'readxl', 'gt')\n\n# Verifica se os pacotes estão instalados e instala se necessário\ninstall.packages(setdiff(x = pacotes,\n                         y = rownames(installed.packages())))\n\n# Carrega os pacotes\nlapply(X = pacotes,\n       FUN = library,\n       character.only = TRUE)\n\nDocumentação:"
  },
  {
    "objectID": "03-BO_02_Datamaid.html#carregando-os-dados-de-exemplo-indicadores-de-saúde",
    "href": "03-BO_02_Datamaid.html#carregando-os-dados-de-exemplo-indicadores-de-saúde",
    "title": "3  Workshop: Crítica e Imputação de Dados: Pacote DataMaid",
    "section": "5.2 Carregando os Dados de Exemplo Indicadores de Saúde",
    "text": "5.2 Carregando os Dados de Exemplo Indicadores de Saúde\nDisponível em: base_dados\n\ndados_datamaid <- read_excel(\"dados/dados_datamaid.xlsx\")\n\ndados_datamaid%>%\n  head(5) %>%\n  gt()\n\n\n\n\n\n  \n    \n    \n      CHAVE\n      IBGE6\n      IBGE7\n      ANO\n      S_TXBRUTAMORT\n      S_TXBRUTAMORTPAD\n      S_TXMOISQCOR45A59\n      S_TXMOAVC45A59\n      S_TXMOATRA15A29\n      S_TXMOHOMI\n      S_TXMOHOMI15A29\n      S_TXMOCANCOLUT\n      S_TXMOCANMA\n      S_TXMOCANPUL\n      S_OBITO60\n      S_NASCBAIXOPESO\n      S_OBINFSIFILS\n      S_OBTETANONEO\n      S_OBRAIVA\n      S_INTERDVHID\n      S_INTERDRSAI\n      S_COBPSF\n      S_NASC7CONSUL\n      S_TETRA\n      S_POLIO\n      S_TRIPLICE\n      S_FAMARELA\n      S_OBMALDEF\n      S_OBITSEMASSIS\n      S_INTERDCV40\n      S_INTERDIAB\n      S_INTERSAP\n      S_INTERSAP1A5\n      S_INTERSAP60\n      S_FRATFEMUR60\n      S_CANCPROST\n      S_INTMEDCOMPLDESMIC\n      S_PARTODESLOCMIC\n      S_PENTA\n      S_TXMODCNT30A69\n      S_ICSAB_MS\n    \n  \n  \n    2000310010\n310010\n3100104\n2000\n7.45\n6.47\n183.49\n0.00\n0.00\n46.54\n61.61\n0\n0.00\n15.51\n64.58\n5.05\nNA\nNA\nNA\n0.19\n0.87\n0.00\n88.89\nNA\n120.72\n56.52\n100.00\n8.33\n0.00\n0.10\n0.11\n10.45\n71.43\n36.33\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n    2000310020\n310020\n3100203\n2000\n3.80\n3.44\n63.33\n63.33\n17.66\n4.47\n17.66\n0\n8.87\n0.00\n56.47\n5.04\nNA\nNA\nNA\n0.29\n0.75\n42.43\n33.42\nNA\n84.01\n64.67\n39.64\n16.47\n4.71\n3.38\n2.74\n38.52\n22.58\n60.66\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n    2000310030\n310030\n3100302\n2000\n5.84\n5.04\n0.00\n119.19\n55.87\n7.49\n0.00\n0\n0.00\n7.49\n69.23\n8.83\nNA\nNA\nNA\n8.60\n8.39\n47.39\n22.61\nNA\n189.14\n114.29\n52.94\n11.54\n6.41\n5.26\n3.72\n52.12\n45.45\n73.21\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n    2000310040\n310040\n3100401\n2000\n6.43\n5.16\n217.86\n0.00\n0.00\n0.00\n0.00\n0\n0.00\n0.00\n68.00\n5.26\nNA\nNA\nNA\n2.61\n3.04\n0.00\n63.16\nNA\n97.10\n55.42\n0.00\n24.00\n0.00\n6.80\n3.73\n46.29\n20.00\n53.70\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n    2000310050\n310050\n3100500\n2000\n6.70\n5.95\n0.00\n140.55\n0.00\n17.41\n33.22\n0\n0.00\n8.70\n49.35\n6.25\nNA\nNA\nNA\n0.29\n2.34\n12.51\n17.50\nNA\n115.90\n108.68\n17.15\n41.56\n35.06\n5.76\n2.10\n30.00\n20.00\n47.86\nNA\nNA\nNA\nNA\nNA\nNA\nNA"
  },
  {
    "objectID": "03-BO_02_Datamaid.html#análise-inicial-dos-dados",
    "href": "03-BO_02_Datamaid.html#análise-inicial-dos-dados",
    "title": "3  Workshop: Crítica e Imputação de Dados: Pacote DataMaid",
    "section": "5.3 Análise Inicial dos Dados",
    "text": "5.3 Análise Inicial dos Dados\nA função makeDataReport produz um relatório de visão geral dos dados em que resume o conteúdo do conjunto de dados e sinaliza possíveis problemas. Esses potenciais erros são identificados executando um conjunto de verificações de validação específicas da classe, de modo que diferentes verificações sejam realizadas em diferentes tipos de variáveis. As etapas de verificação podem ser personalizadas de acordo com a entrada do usuário e/ou tipo de dados da variável inserida\nPara cada variável, um conjunto de funções de pré-verificação (controladas pelo argumento preChecks) é executado primeiro e depois uma bateria de funções é aplicada dependendo da classe da variável."
  },
  {
    "objectID": "03-BO_02_Datamaid.html#trabalhando-com-funções-personalizadas",
    "href": "03-BO_02_Datamaid.html#trabalhando-com-funções-personalizadas",
    "title": "3  Workshop: Crítica e Imputação de Dados: Pacote DataMaid",
    "section": "6.1 Trabalhando com funções personalizadas",
    "text": "6.1 Trabalhando com funções personalizadas\n\n6.1.1 Funções de sumarização\nPode-se criar funções que seja do interesse a verificação. Por exemplo, um função para ocorrências de valores iguais a zero: countZeros()\nCriando a função:\n\ncountZeros <- function(v, ...) {\n  val <- length(which(v == 0))\n  summaryResult(list(feature = \"No. zeros\", result = val, value = val))\n}\n\n\ncountZeros(dados_datamaid$S_TXMOHOMI15A29)\n\nNo. zeros: 12322\n\n\numa outra função útil seria a contagem dos valores atípicos (outliers) em uma variável numérica v usando a abordagem do intervalo interquartil (IQR) com um fator de limiar (threshold):\n\n#Função para Identificar Outliers:\ncountOutliers <- function(v, threshold = 1.5) {\n  q1 <- quantile(v, 0.25)\n  q3 <- quantile(v, 0.75)\n  iqr <- q3 - q1\n  lower_bound <- q1 - threshold * iqr\n  upper_bound <- q3 + threshold * iqr\n  val <- length(which(v < lower_bound | v > upper_bound))\n  summaryResult(list(feature = \"No. outliers\", result = val, value = val))\n}\n\nAlém dessas, outras possibilidades são possíveis, por exemplo, criar uma função que calcule estatísticas (média, mediana, etc.) para uma variável numérica, segmentadas por grupos de uma variável categórica. Isso pode ser útil para entender as diferenças entre grupos:\n\ncalculateStatsByGroup <- function(data, numeric_var, categorical_var) {\n  stats_by_group <- data %>%\n    group_by({{categorical_var}}) %>%\n    summarise(\n      Mean = mean({{numeric_var}}, na.rm = TRUE),\n      Median = median({{numeric_var}}, na.rm = TRUE),\n      SD = sd({{numeric_var}}, na.rm = TRUE)\n    )\n  summaryResult(list(\n    feature = paste(\"Summary Statistics by\", as_label(categorical_var)),\n    result = stats_by_group,\n    value = NULL\n  ))\n}\n\n\n\n6.1.2 Adicionando novas funções ao report\nA inclusão das funções criadas anteriormente são realizadas da seguinte maneira:\n\nmakeDataReport(dados_datamaid, summaries = setSummaries(\n  character = defaultCharacterSummaries(add = c(\"countZeros\", \"countOutliers\")),\n  factor = defaultFactorSummaries(add = c(\"countZeros\", \"countOutliers\")),\n  labelled = defaultLabelledSummaries(add = c(\"countZeros\", \"countOutliers\")),\n  numeric = defaultNumericSummaries(add = c(\"countZeros\", \"countOutliers\")),  \n  integer = defaultIntegerSummaries(add = c(\"countZeros\", \"countOutliers\")),\n  logical = defaultLogicalSummaries(add = c(\"countZeros\", \"countOutliers\"))\n), replace = TRUE, output = \"html\")\n\nError in quantile.default(v, 0.25) : \n  missing values and NaN's not allowed if 'na.rm' is FALSE\n\n\nFunções do DataMaid\n\n\n\n\n\n\n\nname\ndescrição\n\n\n\n\nidentifyCaseIssues\nIdentificar problemas\n\n\nidentifyLoners\nIdentificar variáveis com < 6 obs.\n\n\nidentifyMissing\nIdentificar valores ausentes mal codificados\n\n\nidentifyNums\nIdentificar variáveis numéricas ou inteiras classificadas incorretamente\n\n\nidentifyOutliers\nIdentificar outliers\n\n\nidentifyOutliersTBStyle\nIdentify outliers (Turkish Boxplot style)\n\n\nidentifyWhitespace\nIdentifique espaços em branco prefixados e sufixados\n\n\nisCPR\nIdentify Danish CPR numbers\n\n\nisEmpty\nVerifique se a variável contém apenas um único valor\n\n\nisKey\nVerifique se a variável é uma chave\n\n\nisSingular\nVerifique se a variável contém apenas um único valor\n\n\nisSupported\nVerifique se a classe da variável é suportada pelo dataMaid."
  },
  {
    "objectID": "03-BO_02_Datamaid.html#recursos-adicionais",
    "href": "03-BO_02_Datamaid.html#recursos-adicionais",
    "title": "3  Workshop: Crítica e Imputação de Dados: Pacote DataMaid",
    "section": "6.2 Recursos Adicionais",
    "text": "6.2 Recursos Adicionais\nDocumentação DataMaid - https://github.com/ekstroem/DataMaid\nDocumentação DataMaid : https://cran.r-project.org/web/packages/dataMaid/index.html\n\nvignette(\"extending_dataMaid\")"
  },
  {
    "objectID": "04-BO_03_Validate.html",
    "href": "04-BO_03_Validate.html",
    "title": "4  Workshop: Crítica e Imputação de Dados no R: Validate",
    "section": "",
    "text": "Contato: transformacao.digital@fjp.mg.gov.br\n\n5 Escrevendo e aplicando regras de críticas usando validate\nO pacote validate do R é uma ferramenta poderosa que pode ser usada para validar dados e garantir a qualidade dos resultados de um projeto. Ele oferece uma variedade de funções que podem ser usadas para verificar a validade de dados, incluindo:\n\nValidação de tipos de dados: O pacote validate pode ser usado para verificar se os dados estão no formato correto. Por exemplo, você pode usar a função is.numeric() para verificar se uma variável é um número.\nValidação de valores: O pacote validate pode ser usado para verificar se os valores estão dentro de um intervalo aceitável. Por exemplo, você pode usar a função between() para verificar se um valor está entre dois valores especificados.\nValidação de regras: O pacote validate pode ser usado para verificar se os dados atendem a regras específicas. Por exemplo, você pode usar a função validate() para verificar se um valor é maior que outro valor.\n\nConfrontar os dados com as regras e armazenar os resultados\n\n\n\nVan der Loo; de Jonge (2019).\n\n\nRegras de crítica são expressões que são avaliadas ao ser confrontadas com dados, e resultam em um objeto do tipo ‘logical’ (TRUE ou FALSE)\nVerificações de tipo da variável: is.numeric, is.character,. . .\nComparações: <, <=, ==, identical, !=, %in%, >=, >\nOperadores lógicos: |, &, if, !, all, any\n\n\n6 Padronização nas regras de crítica\nA padronização dos nomes permite que seja possível a identificação da classificação da regra e a presença do atributo de flexibilidade. Define-se a seguinte proposta de nomenclatura para as regras de crítica, conforme Silva (2020):\n1 carácter indicando finalidade + 1 carácter indicando flexibilidade + Sequência numérica\nClassificação por finalidade\n\nTipo (T): refere-se a classe da variável, são realizadas verificações no sentido de identificar se os dados são numéricos, caracteres, lógicos, entre outros.\nValidade ou Intervalo (V): refere-se aos intervalos estabelecidos matematicamente para um dado ou indicador. Verificações de valores positivos, intervalos entre 0 e 1, são exemplos de verificação de validades.\nFluxo (F): quando se estabelece que uma variável só existirá dado que outra existe, pode-se estabelecer uma regra de fluxo. Pode ser usada para os casos de questionários com as verificações dos “pulos”.\nConsistência (C): refere-se aos casos em que se verificam as relações matemáticas com outras variáveis, por exemplo, parcelas de um total não podem ser maiores do que o próprio total.\nDistribuição (D): regras de distribuição estabelecem parâmetros esperados para as estatísticas descritivas da variável como média, moda, mediana, máximo, mínimo e as medidas de dispersão.\n\nClassificação por flexibilidade\n\nFlexível (F): construída com parâmetros esperados, mas caso algum caso falhe a regra, precisa ser investigado o motivo, entendendo se a regra deveria ser outra ou se é o caso de se tratar de um valor atípico que futuramente merecerá uma imputação, ou ainda, simplesmente é um valor atípico explicado por alguma situação.\nInflexível (I): necessariamente precisa ser seguida, uma regra inflexível é rígida e não existe exceção a sua condição estipulada.\n\nExemplos\nTI01: regra de tipo e inflexível\nVI08: regra de validade e inflexível\nCF02: regra de consistência e flexível\nPor definição, regras da classe tipo, validade e fluxo são inflexíveis. As regras da classe consistência podem ser flexíveis e inflexíveis e, por fim, a regra do tipo distribuição é sempre flexível.\n\n\n7 Leitura dos dados\nDisponível em: base_dados\n\n### Instalação e Carregamento do Pacote\n\n# Lista de pacotes necessários\npacotes <- c('validate', 'tidyverse', 'gt','readxl')\n\n# Verifica se os pacotes estão instalados e instala se necessário\ninstall.packages(setdiff(x = pacotes,\n                         y = rownames(installed.packages())))\n\n# Carrega os pacotes\nlapply(X = pacotes,\n       FUN = library,\n       character.only = TRUE)\n\n\n# Carregando dados\n\ndados <- read_excel(\"dados/dados_validate.xlsx\")\n\n\ndados %>%\n  head(5) %>%\n  gt()\n\n\n\n\n\n  \n    \n    \n      IBGE7\n      S_TXBRUTAMORT\n      S_TXBRUTAMORT_t_1\n      S_TXBRUTAMORTPAD\n      S_TXMOISQCOR45A59\n      S_TXMOAVC45A59\n      S_TXMOATRA15A29\n      S_TXMOHOMI\n      S_TXMOHOMI15A29\n      S_TXMOCANCOLUT\n      S_TXMOCANMA\n      S_TXMOCANPUL\n      S_OBITO60\n      S_NASCBAIXOPESO\n      S_OBINFSIFILS\n      S_OBTETANONEO\n      S_OBRAIVA\n      S_INTERDVHID\n      S_INTERDRSAI\n      S_COBPSF\n      S_NASC7CONSUL\n      D_POPP0\n      D_POPT\n      U_CONSSAU\n    \n  \n  \n    3100104\n6.631924\n7.494074\n5.266178\n68.01919\n34.13898\n17.26465\n16.37508\n18.92622\n2.743636\n4.047273\n12.734716\n70.84277\n7.966403\n0.04761905\n0\n0\n1.4818316\n2.424763\n63.56396\n85.62254\n81.32823\n6727.818\nSim\n    3100203\n6.901495\n6.694450\n5.551739\n41.06278\n59.70752\n21.01915\n11.13580\n11.54727\n4.294268\n11.389564\n12.263125\n67.82305\n8.727496\n0.14285714\n0\n0\n0.5450845\n1.695791\n73.72931\n69.30783\n258.86858\n23051.727\nSim\n    3100302\n6.972738\n6.554374\n5.409386\n56.15467\n70.47148\n36.66989\n10.12720\n14.11258\n4.796480\n9.526933\n7.107865\n69.61344\n8.588212\n0.19047619\n0\n0\n8.4660438\n8.706795\n88.25773\n57.10980\n171.93268\n13370.409\nSim\n    3100401\n7.218662\n7.363035\n5.462740\n39.95764\n65.72227\n31.78636\n10.34898\n19.79552\n6.632273\n11.331034\n14.866371\n64.36046\n9.979573\n0.00000000\n0\n0\n0.8072727\n1.296870\n88.93818\n68.81270\n49.09710\n4012.364\nSim\n    3100500\n6.133833\n5.827141\n4.717667\n59.36335\n53.45524\n21.76632\n19.14619\n36.94967\n2.853984\n5.538755\n6.754168\n66.83756\n9.117280\n0.23809524\n0\n0\n0.8704670\n1.241831\n92.52909\n53.73894\n150.48368\n10537.500\nSim\n  \n  \n  \n\n\n\n\nA função validator serve para definir um conjunto de regras de críticas que podem ser aplicadas a diferentes tipos de conjuntos de dados.\nVerificar valores nulos:\n\nVerifique se não há valores nulos em colunas críticas, como “IBGE7,” e outras colunas-chave.\n\nValidar faixas de valores:\n\nVerifique se os valores em colunas numéricas estão dentro de faixas aceitáveis, por exemplo, garantir que as taxas estejam entre 0 e 100.\n\nVerificar valores ausentes em grupos de colunas relacionadas:\n\nVerifique se as colunas relacionadas, como as taxas de mortalidade, têm valores ausentes em conjunto.\n\nVerificar valores booleanos:\n\nVerifique se as colunas com valores lógicos (TRUE/FALSE) estão preenchidas corretamente.\n\nValidar que certas colunas não possuem valores nulos e são numéricas:\n\nCertifique-se de que determinadas colunas têm valores numéricos válidos e não nulos.\n\nA função confront serve para aplicar o conjunto de regras de crítica a uma base de dados específica.\n\n\n8 Regras de tipo (T)\n\n# Crie um conjunto de regras de validade\nregras_tipo <- validator(\n  #Taxa bruta de mortalidade \n  TI01 = is.numeric(S_TXBRUTAMORT),  \n  #Taxa de mortalidade por homicídio da população total\n  TI02 = is.numeric(S_TXMOHOMI),\n  #Taxa de mortalidade por homicídio da população de 15 a 29 anos\n  TI03 = is.numeric(S_TXMOHOMI15A29),\n  #Mortalidade proporcional da população idosa\n  TI04 = is.numeric(S_OBITO60),\n  #Proporção de nascidos vivos com baixo peso\n  TI05 = is.numeric(S_NASCBAIXOPESO),\n  #Casos confirmados notificados de sífilis congênita em menores de 1 ano\n  TI06 = is.numeric(S_OBINFSIFILS),\n  #Casos confirmados notificados de raiva humana\n  TI07 = is.numeric(S_OBRAIVA),\n  #Proporção de internações por doenças de veiculação hídrica\n  TI08 = is.numeric(S_INTERDVHID),\n  #Proporção de internações por doenças relacionadas ao saneamento ambiental inadequado\n  TI09 = is.numeric(S_INTERDRSAI),\n  #Existência de Conselho Municipal de Saúde\n  TI10 = is.character(U_CONSSAU)\n)\n\n# Aplica regras de crítica aos dados\nbase_conf_tipo <- confront(dados, regras_tipo)\n\n# Obtém resumo da aplicação das regras aos dados\nsummary(base_conf_tipo) %>% gt()\n\n\n\n\n\n  \n    \n    \n      name\n      items\n      passes\n      fails\n      nNA\n      error\n      warning\n      expression\n    \n  \n  \n    TI01\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_TXBRUTAMORT)\n    TI02\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_TXMOHOMI)\n    TI03\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_TXMOHOMI15A29)\n    TI04\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_OBITO60)\n    TI05\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_NASCBAIXOPESO)\n    TI06\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_OBINFSIFILS)\n    TI07\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_OBRAIVA)\n    TI08\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_INTERDVHID)\n    TI09\n1\n1\n0\n0\nFALSE\nFALSE\nis.numeric(S_INTERDRSAI)\n    TI10\n1\n1\n0\n0\nFALSE\nFALSE\nis.character(U_CONSSAU)\n  \n  \n  \n\n\n\n# gráfico\nplot(base_conf_tipo)\n\n\n\n\n\n\n9 Regras de validade (V)\n\nregras_validade <- validator(\n  #Taxa bruta de mortalidade \n  VI01 = (S_TXBRUTAMORT>= 0),  \n  #Taxa de mortalidade por homicídio da população total\n  VI02 = (S_TXMOHOMI >= 0),\n  #Taxa de mortalidade por homicídio da população de 15 a 29 anos\n  VI03 = (S_TXMOHOMI15A29 >= 0),\n  #Mortalidade proporcional da população idosa\n  VI04 = (S_OBITO60 >= 0),\n  #Proporção de nascidos vivos com baixo peso\n  VI05 = (S_NASCBAIXOPESO >= 0 & S_NASCBAIXOPESO <= 100),\n  #Casos confirmados notificados de sífilis congênita em menores de 1 ano\n  VI06 = (S_OBINFSIFILS >= 0),\n  #Casos confirmados notificados de raiva humana\n  VI07 = (S_OBRAIVA >= 0),\n  #Proporção de internações por doenças de veiculação hídrica\n  VI08 = (S_INTERDVHID >= 0 & S_INTERDVHID <= 100),\n  #Proporção de internações por doenças relacionadas ao saneamento ambiental inadequado\n  VI09 = (S_INTERDRSAI >= 0 & S_INTERDRSAI <= 100),\n  #Existência de Conselho Municipal de Saúde\n  VI10 = (U_CONSSAU %in% c(\"Sim\",\"Não\"))\n)\n\n# Aplica regras de crítica aos dados\nbase_conf_validade <- confront(dados, regras_validade)\n\n# Obtém resumo da aplicação das regras aos dados\nsummary(base_conf_validade) %>% gt()\n\n\n\n\n\n  \n    \n    \n      name\n      items\n      passes\n      fails\n      nNA\n      error\n      warning\n      expression\n    \n  \n  \n    VI01\n853\n853\n0\n0\nFALSE\nFALSE\n(S_TXBRUTAMORT - 0 >= -1e-08)\n    VI02\n853\n819\n0\n34\nFALSE\nFALSE\n(S_TXMOHOMI - 0 >= -1e-08)\n    VI03\n853\n853\n0\n0\nFALSE\nFALSE\n(S_TXMOHOMI15A29 - 0 >= -1e-08)\n    VI04\n853\n853\n0\n0\nFALSE\nFALSE\n(S_OBITO60 - 0 >= -1e-08)\n    VI05\n853\n853\n0\n0\nFALSE\nFALSE\n(S_NASCBAIXOPESO - 0 >= -1e-08 & S_NASCBAIXOPESO - 100 <= 1e-08)\n    VI06\n853\n853\n0\n0\nFALSE\nFALSE\n(S_OBINFSIFILS - 0 >= -1e-08)\n    VI07\n853\n853\n0\n0\nFALSE\nFALSE\n(S_OBRAIVA - 0 >= -1e-08)\n    VI08\n853\n853\n0\n0\nFALSE\nFALSE\n(S_INTERDVHID - 0 >= -1e-08 & S_INTERDVHID - 100 <= 1e-08)\n    VI09\n853\n853\n0\n0\nFALSE\nFALSE\n(S_INTERDRSAI - 0 >= -1e-08 & S_INTERDRSAI - 100 <= 1e-08)\n    VI10\n853\n835\n18\n0\nFALSE\nFALSE\n(U_CONSSAU %vin% c(\"Sim\", \"Não\"))\n  \n  \n  \n\n\n\n# gráfico\nplot(base_conf_validade)\n\n\n\n\n\n\n10 Regras de consistência (C)\n\nregras_consistencia <- validator(\n  #Taxa bruta de mortalidade \n  CF01 = (S_TXBRUTAMORT/S_TXBRUTAMORT_t_1) <= 1.10,  \n  #Casos confirmados notificados de sífilis congênita em menores de 1 ano\n  CI06 = (S_OBINFSIFILS <= D_POPP0),\n  #Casos confirmados notificados de raiva humana\n  CI07 = (S_OBRAIVA <= D_POPT)\n)\n\n# Aplica regras de crítica aos dados\nbase_conf_consistencia <- confront(dados, regras_consistencia)\n\n# Obtém resumo da aplicação das regras aos dados\nsummary(base_conf_consistencia) %>% gt()\n\n\n\n\n\n  \n    \n    \n      name\n      items\n      passes\n      fails\n      nNA\n      error\n      warning\n      expression\n    \n  \n  \n    CF01\n853\n805\n48\n0\nFALSE\nFALSE\n(S_TXBRUTAMORT/S_TXBRUTAMORT_t_1) <= 1.1\n    CI06\n853\n853\n0\n0\nFALSE\nFALSE\n(S_OBINFSIFILS - D_POPP0 <= 1e-08)\n    CI07\n853\n853\n0\n0\nFALSE\nFALSE\n(S_OBRAIVA - D_POPT <= 1e-08)\n  \n  \n  \n\n\n\n# gráfico\nplot(base_conf_consistencia)\n\n\n\n\n\n\n11 Regras de distribuição (D)\n\nregras_distribuicao <- validator(\n    #Casos confirmados notificados de sífilis congênita em menores de 1 ano\n  DF01 = (S_OBINFSIFILS  < 5),\n  #Casos confirmados notificados de raiva humana\n  DF02 = (S_OBRAIVA < 5),\n  #Proporção de internações por doenças de veiculação hídrica\n  DF03 = (mean(S_INTERDVHID) <= 4),\n  #Proporção de internações por doenças relacionadas ao saneamento ambiental inadequado\n  DF04 = (mean(S_INTERDRSAI) <= 4),\n  #Existência de Conselho Municipal de Saúde\n  DF05 = (mean(U_CONSSAU==\"Sim\") >= 0.95)\n)\n# Aplica regras de crítica aos dados\nbase_conf_distribuicao <- confront(dados, regras_distribuicao)\n\n# Obtém resumo da aplicação das regras aos dados\nsummary(base_conf_distribuicao) %>% gt()\n\n\n\n\n\n  \n    \n    \n      name\n      items\n      passes\n      fails\n      nNA\n      error\n      warning\n      expression\n    \n  \n  \n    DF01\n853\n825\n28\n0\nFALSE\nFALSE\n(S_OBINFSIFILS < 5)\n    DF02\n853\n852\n1\n0\nFALSE\nFALSE\n(S_OBRAIVA < 5)\n    DF03\n1\n1\n0\n0\nFALSE\nFALSE\n(mean(S_INTERDVHID) <= 4)\n    DF04\n1\n1\n0\n0\nFALSE\nFALSE\n(mean(S_INTERDRSAI) <= 4)\n    DF05\n1\n1\n0\n0\nFALSE\nFALSE\n(mean(U_CONSSAU == \"Sim\") >= 0.95)\n  \n  \n  \n\n\n\n# gráfico\nplot(base_conf_distribuicao)\n\n\n\n\n\n\n12 Citação\nGonçalves, C; Marinho,V.. Crítica e Imputação de Dados no R: Validate. Tutorial Transformação Digital. Fundação João Pinheiro, n. 2, 2023. Disponível em: https://rpubs.com/fjp/validate.\n\n\n13 Referências\nSilva, P.L.d.N. (2020). Crítica e Imputação de Dados. Notas de aula - Escola Nacional de Ciências Estatísticas.\nvan der Loo, M. P. J., & de Jonge, E. (2021). Data Validation Infrastructure for R. Journal of Statistical Software, 97(10), 1–31. https://doi.org/10.18637/jss.v097.i10"
  },
  {
    "objectID": "05-BO_04_ACP.html",
    "href": "05-BO_04_ACP.html",
    "title": "5  Análise de componentes principais",
    "section": "",
    "text": "6 Introdução\nA análise de componentes principais (ACP) é uma técnica estatística amplamente utilizada para redução de dimensionalidade e extração de informações relevantes de conjuntos de dados multivariados. O objetivo principal da ACP é transformar um conjunto de variáveis correlacionadas em um novo conjunto de variáveis não correlacionadas, chamadas de componentes principais. Cada componente principal é uma combinação linear das variáveis originais e é ordenado de acordo com a quantidade de variação que ele captura. Isso permite a identificação dos padrões mais significativos dos dados, facilitando a interpretação e visualização. (Manly 1994)\nEstes são alguns exemplos de aplicações:\nEstudos de qualidade de vida: Através da ACP, é possível identificar dimensões principais que influenciam a qualidade de vida em uma determinada região, permitindo que políticas públicas sejam direcionadas de forma mais eficaz.\nAnálise de desigualdade social: A ACP pode ser aplicada em indicadores sociais e econômicos para compreender os principais fatores que contribuem para a desigualdade entre grupos populacionais.\nAnálise de dados de saúde: A ACP é útil para identificar padrões em grandes conjuntos de dados de saúde, como fatores de risco e grupos de doenças.\nEstudos de mercado: A ACP é aplicada em pesquisas de mercado para identificar segmentos de clientes com características semelhantes, ajudando as empresas a direcionar suas estratégias de marketing.\nAnálise de indicadores econômicos: Através da ACP, é possível reduzir um grande número de indicadores econômicos em poucos componentes principais, facilitando a compreensão das principais tendências e correlações na economia.\nPrevisão econômica: A ACP pode ser usada para reduzir a dimensionalidade de séries temporais econômicas e melhorar a precisão das previsões de indicadores macroeconômicos.\nAntes de iniciar o processo de ACP, é necessário carregar as bibliotecas necessárias.\nhttp://www.sthda.com/english/wiki/wiki.php?id_contents=7851"
  },
  {
    "objectID": "05-BO_04_ACP.html#visualização-e-exploração-dos-resultados",
    "href": "05-BO_04_ACP.html#visualização-e-exploração-dos-resultados",
    "title": "5  Análise de componentes principais",
    "section": "7.1 Visualização e exploração dos resultados:",
    "text": "7.1 Visualização e exploração dos resultados:\nPara visualizar a qualidade das variáveis no mapa de fatores, usa-se a função fviz_pca_var()\nO gráfico que exibe a qualidade (cos²) de cada variável em relação aos componentes principais é uma representação visual da contribuição de cada variável para a formação desses componentes. O “cos²” é a proporção da variância da variável original que é explicada pelo componente principal específico.\n\nfviz_pca_var(acp, col.var = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE # Avoid text overlapping \n             )\n\n\n\n\nQuando realizamos a Análise de Componentes Principais (ACP), estamos buscando encontrar novas variáveis (os componentes principais) que sejam combinações lineares das variáveis originais, de modo que eles capturem a maior quantidade possível de variação dos dados. Cada componente principal é uma combinação ponderada das variáveis originais, e a quantidade de variação explicada por cada componente é medida pelos autovalores associados a eles.\nO gráfico de qualidade das variáveis em relação aos componentes principais ajuda a identificar quais variáveis têm uma forte influência na definição de cada componente principal e quais têm uma influência mais fraca. Essa informação é útil para entender quais variáveis são mais importantes para explicar a estrutura dos dados e quais têm menos impacto.\n\n7.1.1 Visualização da comunaliade explicada por cada componente:\nA função fviz_eig é utilizada para exibir a inércia explicada por cada componente principal e o pacote plotly permite deixar o gráfico interativo. Ela mostra o quanto de variação dos dados é explicada por cada componente:\n\nfviz_eig(acp, addlabels=TRUE, ylim = c(0,70))\n\n\n\n\n\n\n7.1.2 Sumarização dos resultados:\nA função facto_summarize é usada para resumir as informações sobre as variáveis e os componentes principais obtidos a partir da ACP. No exemplo, a sumarização é feita para os dois primeiros componentes principais (axes = 1:2):\n\nfacto_summarize(acp, \"var\", axes = 1:2) %>% gt()\n\n\n\n\n\n  \n    \n    \n      name\n      Dim.1\n      Dim.2\n      coord\n      cos2\n      contrib\n    \n  \n  \n    pib\n0.1710860\n0.984893502\n0.9992856\n0.9992856\n26.16030\n    numero_obitos\n0.9857684\n-0.062278615\n0.9756180\n0.9756180\n25.54070\n    desp_saude\n0.9717458\n-0.105023373\n0.9553198\n0.9553198\n25.00931\n    pessoas_pbf\n0.9431881\n-0.005357553\n0.8896325\n0.8896325\n23.28969\n  \n  \n  \n\n\n\n\nAnalisando as coordenadas das variáveis nos dois componentes principais:\nA variável despesas com saude tem uma forte relação positiva com o primeiro componente principal (Dim.1), mas uma relação negativa muito pequena com o segundo componente principal (Dim.2). Isso sugere que essa variável tem um papel dominante na definição do primeiro componente principal, enquanto sua influência no segundo componente é praticamente insignificante.\nA variável populacao_atendida_agua também possui uma relação muito forte e positiva com o primeiro componente principal (Dim.1), mas uma relação negativa muito pequena com o segundo componente principal (Dim.2). Isso indica que essa variável também é um importante contribuinte para a definição do primeiro componente principal.\nAssim como as duas variáveis anteriores, a “populacao_atentida_esgoto” tem uma relação positiva forte com o primeiro componente principal (Dim.1) e uma relação negativa pequena com o segundo componente principal (Dim.2). Isso sugere que essa variável é relevante para o primeiro componente principal.\nA variável pessoas_beneficiarias_pbf tem uma relação positiva relativamente alta com o primeiro componente principal (Dim.1) e uma relação positiva menor com o segundo componente principal (Dim.2). Isso indica que essa variável contribui significativamente para ambos os componentes principais, mas tem uma importância maior no primeiro.\nPor fim, o PIB tem uma relação positiva muito alta com o segundo componente principal (Dim.2) e uma relação positiva menor com o primeiro componente principal (Dim.1). Isso sugere que essa variável é essencialmente representada pelo segundo componente principal e tem uma importância menor no primeiro."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Hoffmann, Rodolfo. 2006. Estatística Para Economistas. 1ª\nedição. Cengage Learning.\n\n\nManly, Bryan F. J. 1994. Multivariate Statistical Methods: A\nPrimer. 2nd ed. Boca Raton: Chapman & Hall/CRC.\n\n\nPetersen, Anne Helby, and Claus Thorn Ekstrøm. 2019.\n“dataMaid: Your Assistant for\nDocumenting Supervised Data Quality Screening in\nR.” Journal of Statistical\nSoftware 90 (6). https://doi.org/10.18637/jss.v090.i06."
  }
]